{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1-Working with RDDs:\n",
    "\n",
    "a) Write a Python program to create an RDD from a local data source.\n",
    "\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# Create a SparkContext\n",
    "sc = SparkContext(\"local\", \"RDD Example\")\n",
    "\n",
    "# Create an RDD from a local data source\n",
    "data = [1, 2, 3, 4, 5]\n",
    "rdd = sc.parallelize(data)\n",
    "b) Implement transformations and actions on the RDD to perform data processing tasks.\n",
    "\n",
    "\n",
    "# Perform transformations on the RDD\n",
    "squared_rdd = rdd.map(lambda x: x ** 2)\n",
    "\n",
    "# Perform actions on the RDD\n",
    "sum_of_squared = squared_rdd.reduce(lambda x, y: x + y)\n",
    "c) Analyze and manipulate data using RDD operations such as map, filter, reduce, or aggregate.\n",
    "\n",
    "# Perform RDD operations\n",
    "filtered_rdd = rdd.filter(lambda x: x % 2 == 0)\n",
    "sum_of_filtered = filtered_rdd.reduce(lambda x, y: x + y)\n",
    "\n",
    "Q2-Spark DataFrame Operations:\n",
    "\n",
    "a) Write a Python program to load a CSV file into a Spark DataFrame.\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"DataFrame Example\").getOrCreate()\n",
    "\n",
    "# Load a CSV file into a DataFrame\n",
    "df = spark.read.csv(\"file.csv\", header=True, inferSchema=True)\n",
    "b) Perform common DataFrame operations such as filtering, grouping, or joining.\n",
    "\n",
    "# Perform DataFrame operations\n",
    "filtered_df = df.filter(df[\"age\"] > 30)\n",
    "grouped_df = df.groupBy(\"city\").count()\n",
    "joined_df = df1.join(df2, on=\"id\", how=\"inner\")\n",
    "c) Apply Spark SQL queries on the DataFrame to extract insights from the data.\n",
    "\n",
    "\n",
    "# Register the DataFrame as a temporary view\n",
    "df.createOrReplaceTempView(\"people\")\n",
    "\n",
    "# Apply Spark SQL queries\n",
    "result = spark.sql(\"SELECT * FROM people WHERE age > 30\")\n",
    "\n",
    "Q3-Spark Streaming:\n",
    "\n",
    "a) Write a Python program to create a Spark Streaming application.\n",
    "\n",
    "\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "# Create a StreamingContext\n",
    "ssc = StreamingContext(sparkContext, batchDuration)\n",
    "\n",
    "# Create a DStream from a streaming source\n",
    "lines = ssc.socketTextStream(\"localhost\", 9999)\n",
    "b) Configure the application to consume data from a streaming source (e.g., Kafka or a socket).\n",
    "\n",
    "# Configure the application to consume data from a socket\n",
    "lines = ssc.socketTextStream(\"localhost\", 9999)\n",
    "c) Implement streaming transformations and actions to process and analyze the incoming data stream.\n",
    "\n",
    "\n",
    "# Perform streaming transformations and actions\n",
    "words = lines.flatMap(lambda line: line.split(\" \"))\n",
    "word_counts = words.map(lambda word: (word, 1)).reduceByKey(lambda x, y: x + y)\n",
    "word_counts.pprint()\n",
    "\n",
    "Q4-Spark SQL and Data Source Integration:\n",
    "\n",
    "a) Write a Python program to connect Spark with a relational database (e.g., MySQL, PostgreSQL).\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"Spark SQL Example\").getOrCreate()\n",
    "\n",
    "# Connect Spark with a relational database\n",
    "url = \"jdbc:mysql://localhost:3306/mydatabase\"\n",
    "properties = {\"user\": \"myuser\", \"password\": \"mypassword\"}\n",
    "df = spark.read.jdbc(url, table=\"mytable\", properties=properties)\n",
    "b) Perform SQL operations on the data stored in the database using Spark SQL.\n",
    "\n",
    "\n",
    "# Perform Spark SQL operations on the DataFrame\n",
    "df.createOrReplaceTempView(\"mytable\")\n",
    "result = spark.sql(\"SELECT * FROM mytable WHERE age > 30\")\n",
    "c) Explore the integration capabilities of Spark with other data sources, such as Hadoop Distributed File System (HDFS) or Amazon S3.\n",
    "\n",
    "\n",
    "# Read data from HDFS or Amazon S3 into a DataFrame\n",
    "df = spark.read.csv(\"hdfs://localhost:9000/data.csv\")\n",
    "df = spark.read.csv(\"s3://bucket-name/data.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
